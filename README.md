# RDS
This is the official repository for "Root Defense Strategies: Ensuring Safety of LLM at the Decoding Level" (Accepted by ACL 2025).

You can find the scripts of running LLMs with human-crafted safety prompts and training continuous safety prompts in scripts. Note that for local running you should set the env variable HF_MODELS that indicates the save folder of LLMs.
